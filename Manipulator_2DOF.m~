%% Code Manipulator 2DOF
% Clean variables
clc, clear all, close all;

% Time defintion variables
t_s = 0.01;
t_final = 90;
t = (0:t_s:t_final);

g = 9.8;
% System parameters L1
b1 = 1;
m1 = 0.8;
l1 = 1;
Iz1= 0.5;

% System parameters L2
b2 = 1;
m2 = 0.8;
l2 = 1;
Iz2= 0.5;


L1 = [b1 , m1, l1, Iz1];
L2 = [b2 , m2, l2, Iz2];

% Initial conditions system       
q = zeros(4, length(t)+1);
q(:, 1) = [0*pi/180;...
           0;...
           0;...
           0];

% Constant defintion
constans = [g, t_s];

% Robot definition
robot = manipulator_system(L1, L2, constans, q(:,1));


% Desired angles of the system
qd = [90*pi/180 + 10*pi/180*sin(0.5*t);...
       0*pi/180 + 10*pi/180*sin(0.5*t)];
   
qdp = [0.5*(10*pi/180)*cos(0.5*t);...
       0.5*(10*pi/180)*cos(0.5*t)];
   
qdpp = [-(0.5)^2*(10*pi/180)*sin(0.5*t);...
        -(0.5)^2*(10*pi/180)*sin(0.5*t)];

% Control gains
kp = 20;
wn = sqrt(kp);
kv = 2*1*wn;

% Learning variable
% Value of P
max_value = (((kv^2)/2)-2)/(sqrt((kv^2)/(4)-1));

gamma = 0.1;

% Learning system
% Transfer funtion definitions
P = tf([1 (kv-gamma) kp-gamma], [0 0 1]);
A = tf([1], [1 kv kp]);
S = tf([0 0 1], [0 1 0]);

% Operator contraction
aux = S*P*A;

% Operator Function
aux_d = c2d(aux, t_s);
[num1d, den1d] = tfdata(aux_d,'v');

% Coeficients learning
b0 = den1d(2);
b1 = den1d(3);
b2 = den1d(4);

a0 = num1d(2);
a1 = num1d(3);
a2 = num1d(4);

% PD control Gains
K1 = kp*eye(2);
K2 = kv*eye(2);

% Controller definition
control = controller(K1, K2, robot);

% Control vector empty
u = zeros(2, length(t));

% Control vector error definition
qe = zeros(2, length(t));
qep = zeros(2, length(t));

% External torque of the system
T_extern = zeros(2, length(t));

% Aux time variable 
t_aux = (t >= 20) & (t < 90);
T_extern(1, t_aux) = 10;
T_extern(2, t_aux) = 10;


% t_aux = (t >= 40) & (t < 50);
% T_extern(1, t_aux) = -10;
% T_extern(2, t_aux) = -10;


% Aux variables learning 
l1_k_1 = 0;
l1_k_2 = 0;
l1_k_3 = 0;

l2_k_1 = 0;
l2_k_2 = 0;
l2_k_3 = 0;

q1_e_1 = 0;
q1_e_2 = 0;
q1_e_3 = 0;

q2_e_1 = 0;
q2_e_2 = 0;
q2_e_3 = 0;

for k = 1:length(t)
    % Control vector 
    qe(:, k) = qd(:, k) - robot.get_positions();
    qep(:, k) = qdp(:, k) - robot.get_velocities();
    
    % Learning rule
    l1_k = [-b0 -b1 -b2]*[l1_k_1; l1_k_2; l1_k_3] + [a0 a1 a2]*[q1_e_1;q1_e_2;q1_e_3];
    l2_k = [-b0 -b1 -b2]*[l2_k_1; l2_k_2; l2_k_3] + [a0 a1 a2]*[q2_e_1;q2_e_2;q2_e_3];
    
    % Control it itslef depents of the variable robot
    %u(:, k) = control.get_control_PD(qd(:, k), qdp(:, k));
%     u(:, k) = control.get_control_PD_Gravity(qd(:, k), qdp(:, k));
    u(:, k) = control.get_control_inverse_full(qd(:, k), qdp(:, k), qdpp(:, k));
    
    learning_control(:, k)= u(:,k) + [l1_k;l2_k];
    
    
    % System evolution
   q(:, k+1) = robot.system_f(learning_control(:, k), T_extern(:, k));
   
   
   % Update signals system
   l1_k_3 = l1_k_2;
   l1_k_2 = l1_k_1;
   l1_k_1 = l1_k;
   
   l2_k_3 = l2_k_2;
   l2_k_2 = l2_k_1;
   l2_k_1 = l2_k;
   
   q1_e_3 = q1_e_2;
   q1_e_2 = q1_e_1;
   q1_e_1 = qe(1, k);
   
   q2_e_3 = q2_e_2;
   q2_e_2 = q2_e_1;
   q2_e_1 = qe(2, k);
end

for k = 1:10:length(t)
    drawpend2(q(:, k), m1, m2, 0.3, l1, l2);
end

save("Data_PD_gravity.mat", "t", "q", "qd", "qdp", "qe", "qep", "u", "L1", "L2")